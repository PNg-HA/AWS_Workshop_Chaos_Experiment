[
{
	"uri": "/",
	"title": "AWS Chaos Experiment",
	"tags": [],
	"description": "",
	"content": "What happens when chaos hits your AWS systems? Are you confident they’ll recover, or will everything crash down?\n"
},
{
	"uri": "/1-cpu-stress/",
	"title": "CPU Stress",
	"tags": [],
	"description": "",
	"content": "Content [Prerequisites] "
},
{
	"uri": "/3/3.1/",
	"title": "Prerequesites",
	"tags": [],
	"description": "",
	"content": "1. Role "
},
{
	"uri": "/1-cpu-stress/1.1/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "1. Create EC2 instance with Windows OS Type and has a public IP: Security group of the instance: IAM instance profile: Check if the Windows instance has SSM: 2. Configure AWS CLI with least privileges (here using AdminFullAccess). 3. Configure CloudWatch Alarm Step 1: Create an SNS topic by selecting Create Topic -\u0026gt; Enter a name in the Name field -\u0026gt; Select Create topic. Subscribe: Step 2: Step 2 will be for CPU Usage. Select instance -\u0026gt; Action -\u0026gt; Monitor and troubleshoot -\u0026gt; Manage CloudWatch alarms Step 3: Create a CloudWatch alarm\nOption 1: Create a CloudWatch alarm on an EC2 instance Set threshhold Option 2: Use AWS CLI to create an Alarm\nCreate an Alarm for CPU usage, NetworkIn, and NetworkOut according to the command in the mostlycloudysky/aws-chaos-experiments repo, replacing YourInstanceId and YourSNSTopicARN:\naws cloudwatch put-metric-alarm --alarm-name CPUUtilizationAlarm --alarm-description \u0026#34;Alarm when CPU exceeds 80%\u0026#34; --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 60 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold --dimensions Name=InstanceId,Value=i-06771d5fe9accdc18 --evaluation-periods 1 --alarm-actions arn:aws:sns:ap-northeast-2:590183822512:HaiAnh-FIS-stress-test aws cloudwatch put-metric-alarm --alarm-name NetworkInAlarm --alarm-description \u0026#34;Alarm when NetworkIn is below 1000 bytes for 1 data point within 1 minute\u0026#34; --metric-name NetworkIn --namespace AWS/EC2 --statistic Average --period 60 --threshold 1000 --comparison-operator LessThanThreshold --dimensions Name=InstanceId,Value=i-06771d5fe9accdc18 --evaluation-periods 1 --alarm-actions arn:aws:sns:ap-northeast-2:590183822512:HaiAnh-FIS-stress-test aws cloudwatch put-metric-alarm --alarm-name NetworkOutAlarm --alarm-description \u0026#34;Alarm when NetworkOut is below 1000 bytes for 1 data point within 1 minute\u0026#34; --metric-name NetworkOut --namespace AWS/EC2 --statistic Average --period 60 --threshold 1000 --comparison-operator LessThanThreshold --dimensions Name=InstanceId,Value=i-06771d5fe9accdc18 --evaluation-periods 1 --alarm-actions arn:aws:sns:ap-northeast-2:590183822512:HaiAnh-FIS-stress-test Check on the console: Check CPU Utilization alarm details: 4. Roles Role for FIS:\nStep 1: Select the Trusted entity as FIS, use case for EC2: "
},
{
	"uri": "/2-network-latency/2.1/",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "The resources were created in the previous step; however, an additional policy is needed for the FIS role.\u0026quot;\n1. Role "
},
{
	"uri": "/2-network-latency/",
	"title": "Network Latency",
	"tags": [],
	"description": "",
	"content": "Content [Prerequisites] "
},
{
	"uri": "/1-cpu-stress/1.2/",
	"title": "Set up",
	"tags": [],
	"description": "",
	"content": "1. Create a template Switching to the console because creating it on AWS CLI resulted in an invalid JSON error: But before encountering the invalid JSON error, if you encounter the error \u0026lsquo;An error occurred (UnauthorizedException) when calling the CreateExperimentTemplate operation: Unauthorized\u0026rsquo;, it means that the IAM role for FIS is missing permissions.\nStep 1: Access the Fault Injection Service page in the console -\u0026gt; Navigate to the Experiment templates page -\u0026gt; Select Create experiment template -\u0026gt; Enter a name. Step 2: Add target Step 3: Add action\nDocument parameters: From the JSON file. Step 4: Review Step 5: Select the IAM role (This role has FIS as the Trusted Entity) Bước 6: Leave the remaining ones as default. Select Create experiment template. But it will result in an error: With a bit of finesse, we can observe that the AWS console automatically handles the input string, but not very \u0026ldquo;elegantly,\u0026rdquo; as it adds escape characters \\ for each double quote, even though we had already added them. You can go to CloudTrail and look for the Event name CreateExperimentTemplate to observe this: Debugging process: error: error displayed to the user. for input: incorrect input from the user entered into the DocumentParameters field. designed: correct input from the DocumentParameters parameter in the JSON file. Fixed input: correct input that the user needs to enter into the DocumentParameters field. The correct input for DocumentParameters is: {\u0026ldquo;commands\u0026rdquo;:[\u0026ldquo;for ($i=0; $i -lt 8; $i++) {Start-Job -ScriptBlock {while ($true) {}}}\u0026rdquo;,\u0026ldquo;Start-Sleep -Seconds 600\u0026rdquo;,\u0026ldquo;Get-Job | Stop-Job\u0026rdquo;]}\nResult: The \u0026ldquo;Export \u0026hellip;\u0026rdquo; section explains why running AWS CLI on PowerShell results in an error. This is because it must be run on Linux and must be executed as specified in the export section, rather than being omitted as in the repo:\naws fis create-experiment-template \\ --cli-input-json \u0026#39;{ \u0026#34;description\u0026#34;: \u0026#34;Experiment to inject CPU stress on EC2 instances\u0026#34;, \u0026#34;targets\u0026#34;: { \u0026#34;TargetInstances\u0026#34;: { \u0026#34;resourceType\u0026#34;: \u0026#34;aws:ec2:instance\u0026#34;, \u0026#34;resourceArns\u0026#34;: [ \u0026#34;arn:aws:ec2:ap-northeast-2:590183822512:instance/i-06771d5fe9accdc18\u0026#34; ], \u0026#34;selectionMode\u0026#34;: \u0026#34;ALL\u0026#34; } }, \u0026#34;actions\u0026#34;: { \u0026#34;InjectCPUStress\u0026#34;: { \u0026#34;actionId\u0026#34;: \u0026#34;aws:ssm:send-command\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Inject CPU stress on target EC2 instances\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;documentArn\u0026#34;: \u0026#34;arn:aws:ssm:ap-northeast-2::document/AWS-RunPowerShellScript\u0026#34;, \u0026#34;documentParameters\u0026#34;: \u0026#34;{\\\u0026#34;commands\\\u0026#34;:[\\\u0026#34;for ($i=0; $i -lt 8; $i++) {Start-Job -ScriptBlock {while ($true) {}}}\\\u0026#34;,\\\u0026#34;Start-Sleep -Seconds 600\\\u0026#34;,\\\u0026#34;Get-Job | Stop-Job\\\u0026#34;]}\u0026#34;, \u0026#34;duration\u0026#34;: \u0026#34;PT20M\u0026#34; }, \u0026#34;targets\u0026#34;: { \u0026#34;Instances\u0026#34;: \u0026#34;TargetInstances\u0026#34; } } }, \u0026#34;stopConditions\u0026#34;: [ { \u0026#34;source\u0026#34;: \u0026#34;none\u0026#34; } ], \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::590183822512:role/HaiAnh-FIS\u0026#34;, \u0026#34;tags\u0026#34;: {}, \u0026#34;experimentOptions\u0026#34;: { \u0026#34;accountTargeting\u0026#34;: \u0026#34;single-account\u0026#34;, \u0026#34;emptyTargetResolutionMode\u0026#34;: \u0026#34;fail\u0026#34; } }\u0026#39; Create experiment template on Linux: Full output: Check on the console: 2. Run Template Step 1: Switch to \u0026ldquo;Start experiment CLI command\u0026rdquo; to see how to run the template on the CLI: Or run it on the console by going to the Experiment templates page and selecting \u0026lsquo;Start experiment\u0026rsquo;: Step 2: Enter \u0026lsquo;start\u0026rsquo;: Result: While running, check CloudWatch: Check SSM: Wait a few minutes: When that happens, go back to the experiment page: Check detailed Action: Timeline: "
},
{
	"uri": "/2-network-latency/2.2/",
	"title": "Set up",
	"tags": [],
	"description": "",
	"content": "The resources were created in the previous step; however, an additional policy is needed for the FIS role.\u0026quot;\n1. Create a Template Step 1: Go to the Fault Injection Service page on the console -\u0026gt; Experiment templates page -\u0026gt; Select Create experiment template -\u0026gt; Enter a name Step 2: Add target Step 3: Add action\nDocument parameters: From the JSON file. Document parameters execute the purpose of delaying 1 second for network traffic passing through port 8080, using 2 commands:\nnetsh interface portproxy add v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=127.0.0.1 Create a port proxy rule: forward traffic from the Internet to the loopback address on port 8080 netsh interface portproxy set v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=127.0.0.1 delay=1000 Edit rule from command 1: 1-second delay for forwarded traffic Step 4: Review Step 5: Choose IAM role (This role has Trusted Entity as FIS) Step 6: Leave the remaining options as default. Select Create experiment template Enter \u0026lsquo;Create\u0026rsquo;: Template created successfully: Go to the Export section to see how to install this template using CMD: aws fis create-experiment-template ^ --cli-input-json \u0026#34;{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Experiment to inject network latency on EC2 Windows instance\\\u0026#34;,\\\u0026#34;targets\\\u0026#34;:{\\\u0026#34;TargetInstances\\\u0026#34;:{\\\u0026#34;resourceType\\\u0026#34;:\\\u0026#34;aws:ec2:instance\\\u0026#34;,\\\u0026#34;resourceArns\\\u0026#34;:[\\\u0026#34;arn:aws:ec2:ap-northeast-2:590183822512:instance/i-06771d5fe9accdc18\\\u0026#34;],\\\u0026#34;selectionMode\\\u0026#34;:\\\u0026#34;ALL\\\u0026#34;}},\\\u0026#34;actions\\\u0026#34;:{\\\u0026#34;InjectNetworkLatency\\\u0026#34;:{\\\u0026#34;actionId\\\u0026#34;:\\\u0026#34;aws:ssm:send-command\\\u0026#34;,\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Inject network latency on target EC2 instances\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:{\\\u0026#34;documentArn\\\u0026#34;:\\\u0026#34;arn:aws:ssm:ap-northeast-2::document/AWS-RunPowerShellScript\\\u0026#34;,\\\u0026#34;documentParameters\\\u0026#34;:\\\u0026#34;{\\\\\\\u0026#34;commands\\\\\\\u0026#34;:[\\\\\\\u0026#34;etsh interface portproxy add v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=127.0.0.1\\\\\\\u0026#34;, \\\\\\\u0026#34;netsh interface portproxy set v4tov4 listenport=8080 listenaddress=0.0.0.0 connectport=8080 connectaddress=127.0.0.1 delay=1000\\\\\\\u0026#34;, \\\\\\\u0026#34;Write-Output \u0026#39;Introduced 1000ms network latency using netsh.\u0026#39;\\\\\\\u0026#34;]}\\\u0026#34;,\\\u0026#34;duration\\\u0026#34;:\\\u0026#34;PT20M\\\u0026#34;},\\\u0026#34;targets\\\u0026#34;:{\\\u0026#34;Instances\\\u0026#34;:\\\u0026#34;TargetInstances\\\u0026#34;}}},\\\u0026#34;stopConditions\\\u0026#34;:[{\\\u0026#34;source\\\u0026#34;:\\\u0026#34;none\\\u0026#34;}],\\\u0026#34;roleArn\\\u0026#34;:\\\u0026#34;arn:aws:iam::590183822512:role/HaiAnh-FIS\\\u0026#34;,\\\u0026#34;tags\\\u0026#34;:{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;inject network latency\\\u0026#34;},\\\u0026#34;experimentOptions\\\u0026#34;:{\\\u0026#34;accountTargeting\\\u0026#34;:\\\u0026#34;single-account\\\u0026#34;,\\\u0026#34;emptyTargetResolutionMode\\\u0026#34;:\\\u0026#34;fail\\\u0026#34;}}\u0026#34; 2. Run the template Step 1: You can run the template on the CLI using the command\naws fis start-experiment --experiment-template-id \u0026lt;template-id\u0026gt; In this case specifically:\naws fis start-experiment --experiment-template-id EXT9VzeDWJYFwcJN4 Or run it on the console by going to the Experiment templates page, selecting the template you just created -\u0026gt; \u0026lsquo;Start experiment\u0026rsquo;: Step 2: Enter \u0026lsquo;start\u0026rsquo; While running, check SSM: Go back to the FIS experiment page: Check detailed Action: Timeline: "
},
{
	"uri": "/3/3.2/",
	"title": "Set up",
	"tags": [],
	"description": "",
	"content": "1. Create template Step 1: Go to the Fault Injection Service page on the console -\u0026gt; Experiment templates page -\u0026gt; Select Create experiment template -\u0026gt; Name it Step 2: Add target Step 3: Add action\nUncheck the \u0026lsquo;Completed if instances terminated\u0026rsquo; line in this case because we are testing while the instance is running. Step 4: Review Step 5: Select IAM role (This role has a Trusted Entity of FIS) Step 6: Leave the remaining settings as default. Select Create experiment template. Enter \u0026ldquo;Create\u0026rdquo;: Successfully created the template: Go to the Export section to see how to install this template in CMD: aws fis create-experiment-template ^ --cli-input-json \u0026#34;{\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Experiment to stop EC2 instances\\\u0026#34;,\\\u0026#34;targets\\\u0026#34;:{\\\u0026#34;TargetInstances\\\u0026#34;:{\\\u0026#34;resourceType\\\u0026#34;:\\\u0026#34;aws:ec2:instance\\\u0026#34;,\\\u0026#34;resourceArns\\\u0026#34;:[\\\u0026#34;arn:aws:ec2:ap-northeast-2:590183822512:instance/i-06771d5fe9accdc18\\\u0026#34;],\\\u0026#34;selectionMode\\\u0026#34;:\\\u0026#34;ALL\\\u0026#34;}},\\\u0026#34;actions\\\u0026#34;:{\\\u0026#34;StopInstances\\\u0026#34;:{\\\u0026#34;actionId\\\u0026#34;:\\\u0026#34;aws:ec2:stop-instances\\\u0026#34;,\\\u0026#34;description\\\u0026#34;:\\\u0026#34;Stop target EC2 instance\\\u0026#34;,\\\u0026#34;parameters\\\u0026#34;:{\\\u0026#34;completeIfInstancesTerminated\\\u0026#34;:\\\u0026#34;false\\\u0026#34;},\\\u0026#34;targets\\\u0026#34;:{\\\u0026#34;Instances\\\u0026#34;:\\\u0026#34;TargetInstances\\\u0026#34;}}},\\\u0026#34;stopConditions\\\u0026#34;:[{\\\u0026#34;source\\\u0026#34;:\\\u0026#34;none\\\u0026#34;}],\\\u0026#34;roleArn\\\u0026#34;:\\\u0026#34;arn:aws:iam::590183822512:role/HaiAnh-FIS\\\u0026#34;,\\\u0026#34;tags\\\u0026#34;:{\\\u0026#34;Name\\\u0026#34;:\\\u0026#34;stop-instance\\\u0026#34;},\\\u0026#34;experimentOptions\\\u0026#34;:{\\\u0026#34;accountTargeting\\\u0026#34;:\\\u0026#34;single-account\\\u0026#34;,\\\u0026#34;emptyTargetResolutionMode\\\u0026#34;:\\\u0026#34;fail\\\u0026#34;}}\u0026#34; 2. Run the template Step 1: You can run the template on the CLI using the command\naws fis start-experiment --experiment-template-id \u0026lt;template-id\u0026gt; In this particular case:\naws fis start-experiment --experiment-template-id EXTADVWqNsdEa5UBa Or run it on the console by going to the Experiment templates page, selecting the template you just created, and then clicking \u0026lsquo;Start experiment\u0026rsquo;. Select Start experiment: Step 2: Enter \u0026ldquo;start\u0026rdquo; According to the configuration, FIS will link to the EC2 API to stop the instance, so there is no need to check SSM.\nRun for a few seconds. When done, return to the experiment page: Check the detailed Action of the experiment: "
},
{
	"uri": "/1-cpu-stress/1.3/",
	"title": "Check CloudWatch alarm &amp; Notification",
	"tags": [],
	"description": "",
	"content": "1. CloudWatch alarm CPU Utilization: NetworkIn: NetworkOut: 2. Received a warning email Mail CPU Utilization: Mail NetworkIn alarm: Mail NetworkOut alarm: "
},
{
	"uri": "/2-network-latency/2.3/",
	"title": "Check CloudWatch alarm &amp; Notification",
	"tags": [],
	"description": "",
	"content": "1. CloudWatch alarm CPU Utilization: normal NetworkIn: NetworkOut: 2. Receive a warning email Mail NetworkIn alarm: Mail NetworkOut alarm: "
},
{
	"uri": "/3/3.3/",
	"title": "Check Instance",
	"tags": [],
	"description": "",
	"content": "Go to CloudTrail to check and see an event StopInstances occurred with the user name being the ID of the template just created:\nMonitor the StopInstances event:\nThus, the instance has been successfully stopped:\n"
},
{
	"uri": "/3/",
	"title": "Stop EC2 Instances",
	"tags": [],
	"description": "",
	"content": "The resources have been created in the previous section; however, an additional policy is needed for the FIS role.\n"
},
{
	"uri": "/4/",
	"title": "Clean up",
	"tags": [],
	"description": "",
	"content": "Delete GitHub repository According to GitHub Action billing, usage is free for standard GitHub-hosted runners in public repositories, which is in this workshop senario. However, for private repositories, each GitHub account receives a certain amount of free minutes and storage for use with GitHub-hosted runners, depending on the account\u0026rsquo;s plan. In summary, if you don\u0026rsquo;t activate the GitHub Action flow, you are free of charge even for all workflow we have builded throughout this workshop.\nGo to the Setting section. Scroll down to the end to click the \u0026ldquo;Delete this repository\u0026rdquo; button. A pop-up show up. Click \u0026ldquo;I want to delete this repository.\u0026rdquo; This workshop is conducted during August, 2024. At this time, I choose GitHub Nobile to verify for any action in GitHub console, including deleting GitHub repository.\nRemove AWS FIS resources According to AWS Prcing, AWS FIS just charges for the running experiment. So the templates you have configured are free of charge if you keep them without running the experiments.\nNavigate to AWS FIS Experiment templates page. Choose deployed templates -\u0026gt; Click Actions. Choose \u0026ldquo;Delete experiment template\u0026rdquo;. A pop-up shows up. Type \u0026ldquo;delete\u0026rdquo; in the input and click \u0026ldquo;Delete experiment template\u0026rdquo; button. Remove AWS CloudWatch Alarms Navigate to AWS CloudWatch Alarm page.\nChoose the alarm you have created. Select Action buttion -\u0026gt; Select Delete. A pop-up shows up. Click Delete button. Remove AWS EC2 instance Access the EC2 dashboard.\nNavigate to Instances.\nChoose the instances associated with the lab.\nClick on Instance state.\nSelect Terminate instance. "
},
{
	"uri": "/1-cpu-stress/1.4/",
	"title": "Detect &amp; Remediate CPU Stress with scripts",
	"tags": [],
	"description": "",
	"content": "Part 1: Detect 1. Prerequisites Required:\nPython 3.9 or higher. GitHub account. GitHub token. GitHub repository. How to create a GitHub token:\nStep 1: After logging in to the GitHub website, go to github.com/settings/tokens -\u0026gt; Select Generate new token: Step 2: Select Generate new token (classic): Step 3: Configure the duration and permissions as needed (I configure full permissions) and then select \u0026ldquo;Generate token\u0026rdquo;: Step 4: Save this token for use later.\nHow to create a GitHub repository: Refer to https://docs.github.com/en/repositories/creating-and-managing-repositories/quickstart-for-repositories.\nIn this article, I created a repository named AWS-Chaos-Experiments on the account PNG-HA. 2. Set up a. Edit the script\nEdit the code in the file scripts/detect_issues.py in the reference repository (mostlycloudysky/aws-chaos-experiments) to use credentials directly in the code. This is not recommended as it is not a best practice for security.\nDEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; (syntax is user/repo) DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_*******\u0026#34; DEFAULT_CLOUDWATCH_ALARM_NAME = \u0026#34;CPUUtilizationAlarm\u0026#34; Script has been updated:\nimport os import boto3 import requests from datetime import datetime, timedelta # Default environment variables DEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_***********************\u0026#34; DEFAULT_CLOUDWATCH_ALARM_NAME = \u0026#34;CPUUtilizationAlarm\u0026#34; def detect_cpu_stress(): print(\u0026#34;Detecting CPU stress issues...\u0026#34;) cloudwatch = boto3.client(\u0026#34;cloudwatch\u0026#34;, region_name=os.getenv(\u0026#34;AWS_REGION\u0026#34;, DEFAULT_AWS_REGION)) alarm_name = os.getenv(\u0026#34;CLOUDWATCH_ALARM_NAME\u0026#34;, DEFAULT_CLOUDWATCH_ALARM_NAME) response = cloudwatch.describe_alarms(AlarmNames=[alarm_name]) alarms = response[\u0026#34;MetricAlarms\u0026#34;] if not alarms: print(\u0026#34;No alarms found with the specified name.\u0026#34;) return alarm_state = alarms[0][\u0026#34;StateValue\u0026#34;] if alarm_state == \u0026#34;ALARM\u0026#34;: instance_id = alarms[0][\u0026#34;Dimensions\u0026#34;][0][ \u0026#34;Value\u0026#34; ] # Assuming the alarm is set on a single EC2 instance create_github_issue(instance_id) else: print(\u0026#34;No CPU stress issues detected.\u0026#34;) def create_github_issue(instance_id): repo = os.getenv(\u0026#34;GITHUB_REPO\u0026#34;, DEFAULT_GITHUB_REPO) token = os.getenv(\u0026#34;GITHUB_TOKEN\u0026#34;, DEFAULT_GITHUB_TOKEN) url = f\u0026#34;https://api.github.com/repos/{repo}/issues\u0026#34; headers = {\u0026#34;Authorization\u0026#34;: f\u0026#34;token {token}\u0026#34;} issue_title = f\u0026#34;EC2 Instance {instance_id} CPU Stress Detected\u0026#34; issue_body = f\u0026#34;The CloudWatch alarm for EC2 instance {instance_id} is in the ALARM state, indicating high CPU utilization. Remediation action is required.\u0026#34; issue = {\u0026#34;title\u0026#34;: issue_title, \u0026#34;body\u0026#34;: issue_body} response = requests.post(url, headers=headers, json=issue) if response.status_code == 201: print(f\u0026#34;GitHub issue created for instance {instance_id}\u0026#34;) else: print( f\u0026#34;Failed to create GitHub issue for instance {instance_id}: {response.text}\u0026#34; ) if __name__ == \u0026#34;__main__\u0026#34;: detect_cpu_stress() b. Perform instance stop detection\nStep 1: Run the script (simultaneously run the cpu_stress experiment) Step 2: Check the issue on your personal GitHub repo Step 3: Observe issue details The Instance ID in the issue is the same as the EC instance ID mentioned above. Thus, the instance experiencing CPU stress has been successfully detected by the script.\nPart 2: Remediate Reference: file scripts/remediate_stopped_instances.py from the repo mostlycloudysky/aws-chaos-experiments.\n1. Edit the script As in Part 1, place the credentials into the script. Besides the region, repository, and token, this script requires:\nDEFAULT_GITHUB_ISSUE_NUMBER: the number (#) of the issue you want to address. Additionally, an environment variable for issue_body is needed, but I will directly add this value as the default for the getenv() function.\nScript has been updated:\nimport os import boto3 import requests from datetime import datetime, timedelta # Default environment variables DEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_***********************\u0026#34; DEFAULT_CLOUDWATCH_ALARM_NAME = \u0026#34;CPUUtilizationAlarm\u0026#34; DEFAULT_GITHUB_ISSUE_NUMBER = \u0026#34;\u0026lt;number\u0026gt;\u0026#34; def detect_cpu_stress(): print(\u0026#34;Detecting CPU stress issues...\u0026#34;) cloudwatch = boto3.client(\u0026#34;cloudwatch\u0026#34;, region_name=os.getenv(\u0026#34;AWS_REGION\u0026#34;, DEFAULT_AWS_REGION)) alarm_name = os.getenv(\u0026#34;CLOUDWATCH_ALARM_NAME\u0026#34;, DEFAULT_CLOUDWATCH_ALARM_NAME) response = cloudwatch.describe_alarms(AlarmNames=[alarm_name]) alarms = response[\u0026#34;MetricAlarms\u0026#34;] if not alarms: print(\u0026#34;No alarms found with the specified name.\u0026#34;) return alarm_state = alarms[0][\u0026#34;StateValue\u0026#34;] if alarm_state == \u0026#34;ALARM\u0026#34;: instance_id = alarms[0][\u0026#34;Dimensions\u0026#34;][0][ \u0026#34;Value\u0026#34; ] # Assuming the alarm is set on a single EC2 instance create_github_issue(instance_id) else: print(\u0026#34;No CPU stress issues detected.\u0026#34;) def create_github_issue(instance_id): repo = os.getenv(\u0026#34;GITHUB_REPO\u0026#34;, DEFAULT_GITHUB_REPO) token = os.getenv(\u0026#34;GITHUB_TOKEN\u0026#34;, DEFAULT_GITHUB_TOKEN) url = f\u0026#34;https://api.github.com/repos/{repo}/issues\u0026#34; headers = {\u0026#34;Authorization\u0026#34;: f\u0026#34;token {token}\u0026#34;} issue_title = f\u0026#34;EC2 Instance {instance_id} CPU Stress Detected\u0026#34; issue_body = f\u0026#34;The CloudWatch alarm for EC2 instance {instance_id} is in the ALARM state, indicating high CPU utilization. Remediation action is required.\u0026#34; issue = {\u0026#34;title\u0026#34;: issue_title, \u0026#34;body\u0026#34;: issue_body} response = requests.post(url, headers=headers, json=issue) if response.status_code == 201: print(f\u0026#34;GitHub issue created for instance {instance_id}\u0026#34;) else: print( f\u0026#34;Failed to create GitHub issue for instance {instance_id}: {response.text}\u0026#34; ) if __name__ == \u0026#34;__main__\u0026#34;: detect_cpu_stress() 2. Resolve the issue Run the script to fix issue #4: The script will stop the heavy job on the instance (and will not close the issue).\nMonitor via CloudWatch: After the CPU exceeds the threshold (at the time of the alarm), begin to gradually reduce (after activating the remediation script).\nCheck the instance through CloudTrail events: Check the \u0026lsquo;Run command\u0026rsquo; that was executed for remediation in System Manager: Noticed overlapping timestamps (on SSM and on CloudTrail are UTC). Additionally, when stopping the job, the experiment does not fail: Thus, the detection and resolution of CPU stress have been successfully implemented.\n"
},
{
	"uri": "/2-network-latency/2.4/",
	"title": "Detect &amp; Remediate Network Latency with scripts",
	"tags": [],
	"description": "",
	"content": "Part 1: Detect 1. Prerequisites As in the CPU Stress section\n2. Set up a. Edit the script\nEdit the code in the file scripts/detect_issues.py in the reference repository (mostlycloudysky/aws-chaos-experiments) to use credentials directly in the code. This is not recommended as it is not a best practice for security.\nDEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; (syntax is user/repo) DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_**************************\u0026#34; DEFAULT_CLOUDWATCH_ALARM_NAME = \u0026#34;NetworkInAlarm\u0026#34; (there are 2 alarms for the network, but the reference repo uses NetworkIn) Script has been updated: b. Perform network latency detection\nStep 1: Run the script (simultaneously run the experiment with a network latency delay of 30 seconds due to the instance being too powerful). Step 2: Check the issue on your personal GitHub repo Step 3: Observe the issue details. The Instance ID in the issue matches the EC instance ID mentioned above. This indicates that the instance experiencing network latency was successfully detected using the script.\nPart 2: Remediate Reference: the scripts/remediate_network_latency.py file from the mostlycloudysky/aws-chaos-experiments repository.\n1. Edit the script As in part 1, place the credentials into the script. Besides the region, repo, and token, this script also requires:\nDEFAULT_GITHUB_ISSUE_NUMBER: The sequence number (#) of the issue to be resolved Additionally, an environment variable is needed for the variable issue_body, but I will directly add this value as the default for the getenv() function.\nScript has been updated:\nimport os import boto3 import requests import re import base64 # Default environment variables DEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_***********************\u0026#34; DEFAULT_GITHUB_ISSUE_NUMBER = \u0026#34;5\u0026#34; def run_ssm_document(instance_id): ssm = boto3.client(\u0026#34;ssm\u0026#34;, region_name=os.getenv(\u0026#34;AWS_REGION\u0026#34;, DEFAULT_AWS_REGION)) script = \u0026#34;echo Hello\u0026#34; encoded_script = base64.b64encode(script.encode(\u0026#34;utf-8\u0026#34;)).decode(\u0026#34;utf-8\u0026#34;) response = ssm.start_automation_execution( DocumentName=\u0026#34;AWSSupport-StartEC2RescueWorkflow\u0026#34;, Parameters={ \u0026#34;InstanceId\u0026#34;: [instance_id], \u0026#34;AllowEncryptedVolume\u0026#34;: [\u0026#34;True\u0026#34;], \u0026#34;OfflineScript\u0026#34;: [encoded_script], }, ) execution_id = response[\u0026#34;AutomationExecutionId\u0026#34;] print(f\u0026#34;Started SSM document on instance {instance_id}: {execution_id}\u0026#34;) def parse_body(issue_body): match = re.search(r\u0026#34;EC2 instance (\\bi-\\w+\\b)\u0026#34;, issue_body) if match: return match.group(1) else: raise ValueError(\u0026#34;Instance ID not found in issue body\u0026#34;) def remediate(): issue_body = os.getenv(\u0026#34;ISSUE_BODY\u0026#34;, \u0026#34;The NetworkIn alarm for EC2 instance i-06771d5fe9accdc18 has been triggered. Remediation action is required.\u0026#34;) try: instance_id = parse_body(issue_body) print(f\u0026#34;Instance ID to remediate: {instance_id}\u0026#34;) run_ssm_document(instance_id) except Exception as e: print(f\u0026#34;Error during remediation: {e}\u0026#34;) reopen_issue() def reopen_issue(): issue_number = os.getenv(\u0026#34;ISSUE_NUMBER\u0026#34;, DEFAULT_GITHUB_ISSUE_NUMBER) repo = os.getenv(\u0026#34;GITHUB_REPO\u0026#34;, DEFAULT_GITHUB_REPO) token = os.getenv(\u0026#34;GITHUB_TOKEN\u0026#34;, DEFAULT_GITHUB_TOKEN) url = f\u0026#34;https://api.github.com/repos/{repo}/issues/{issue_number}\u0026#34; headers = {\u0026#34;Authorization\u0026#34;: f\u0026#34;token {token}\u0026#34;} data = {\u0026#34;state\u0026#34;: \u0026#34;open\u0026#34;} response = requests.patch(url, headers=headers, json=data) if response.status_code == 200: print(f\u0026#34;Reopened issue {issue_number}\u0026#34;) else: print(f\u0026#34;Failed to reopen issue {issue_number}: {response.content}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: remediate() 2. Resolve the issue Run the script to fix issue #: The most important part of the script is running the AWSSupport-StartEC2RescueWorkflow document (see https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-startec2rescueworkflow.html). The script launches a new instance (with a name containing \u0026ldquo;rescue\u0026rdquo;), attaches the volume from the problematic instance, and then fixes it using the pre-configured script (variable \u0026ldquo;script\u0026rdquo;). However, it is confusing that the script only runs “echo Hello” instead of making any repairs.\nCheck the logic through CloudTrail: Check the instance on the EC2 page. Initially, the EC2Rescue instance was created: A few seconds later, start shutting down the instance in the issue to detach the volume: Then, the instance for the experiment was stopped completely: A few minutes later, the new instance shuts down, and the instance for the experiment is restarted. Monitor via CloudWatch: Thus, the detection and resolution of the network latency issue on the EC2 instance have been successfully implemented.\n"
},
{
	"uri": "/3/3.4/",
	"title": "Detect &amp; Remediate Stopped Instances with scripts",
	"tags": [],
	"description": "",
	"content": "Part 1: Detect 1. Prerequisites Like the CPU Stress section.\n2. Set up a. Edit the script\nEdit the code in the file scripts/detect_issues.py in the reference repository (mostlycloudysky/aws-chaos-experiments) to use credentials in the code. Note that this approach is not recommended as it is not a best practice for security.\nDEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; (syntax is user/repo) DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_*******\u0026#34; Script has been updated:\nimport os import boto3 import requests import json # Default environment variables DEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_***********************\u0026#34; def detect_issues(): print(\u0026#34;Detecting issues...\u0026#34;) # Use environment variables or fall back to default values aws_region = os.getenv(\u0026#34;AWS_REGION\u0026#34;, DEFAULT_AWS_REGION) ec2 = boto3.client(\u0026#34;ec2\u0026#34;, region_name=aws_region) response = ec2.describe_instances( Filters=[{\u0026#34;Name\u0026#34;: \u0026#34;instance-state-name\u0026#34;, \u0026#34;Values\u0026#34;: [\u0026#34;stopped\u0026#34;]}] ) instance_ids = [] for reservation in response[\u0026#34;Reservations\u0026#34;]: for instance in reservation[\u0026#34;Instances\u0026#34;]: instance_ids.append(instance[\u0026#34;InstanceId\u0026#34;]) if not instance_ids: print(\u0026#34;No issues detected.\u0026#34;) return # Call create_github_issues for each instance for instance_id in instance_ids: create_github_issues(instance_id) def create_github_issues(instance_id): # Use environment variables or fall back to default values repo = os.getenv(\u0026#34;GITHUB_REPO\u0026#34;, DEFAULT_GITHUB_REPO) token = os.getenv(\u0026#34;GITHUB_TOKEN\u0026#34;, DEFAULT_GITHUB_TOKEN) url = f\u0026#34;https://api.github.com/repos/{repo}/issues\u0026#34; headers = {\u0026#34;Authorization\u0026#34;: f\u0026#34;token {token}\u0026#34;} issue_title = f\u0026#34;EC2 Instance {instance_id} Stopped\u0026#34; issue_body = f\u0026#34;The EC2 instance {instance_id} is currently stopped. Remediation action is required.\u0026#34; issue = {\u0026#34;title\u0026#34;: issue_title, \u0026#34;body\u0026#34;: issue_body} response = requests.post(url, headers=headers, json=issue) if response.status_code == 201: print(f\u0026#34;GitHub issue created for instance {instance_id}\u0026#34;) else: print(f\u0026#34;Failed to create GitHub issue for instance {instance_id}: {response.text}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: detect_issues() b. Perform instance stop detection\nStep 1: Run the script Step 2: Check the issue on your personal GitHub repo Step 3: Observe the issue details. Instance ID in the issue is similar to the EC instance ID mentioned above. This means that the instance has been successfully detected as stopped by the script.\nPart 2: Remediate Reference: file scripts/remediate_stopped_instances.py from the repo mostlycloudysky/aws-chaos-experiments.\n1. Edit the script As in Part 1, place the credentials into the script. In addition to the region, repo, and token, this script requires:\nDEFAULT_GITHUB_ISSUE_NUMBER: the issue number (#) that the issue wants to address Additionally, an environment variable for the issue_body variable is needed, but I will directly add this value as the default for the getenv() function.\nScript has been updated:\nimport os import boto3 import re import requests # Default environment variables DEFAULT_AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; DEFAULT_GITHUB_REPO = \u0026#34;PNg-HA/AWS-Chaos-Experiments\u0026#34; DEFAULT_GITHUB_TOKEN = \u0026#34;ghp_***********************\u0026#34; DEFAULT_GITHUB_ISSUE_NUMBER = \u0026#34;\u0026lt;number\u0026gt;\u0026#34; def start_instance(instance_id): aws_region = os.getenv(\u0026#34;AWS_REGION\u0026#34;, DEFAULT_AWS_REGION) ec2 = boto3.client(\u0026#34;ec2\u0026#34;, region_name=aws_region) response = ec2.start_instances(InstanceIds=[instance_id]) print(f\u0026#34;Starting instance {instance_id}: {response}\u0026#34;) def parse_issue_body(issue_body): # Use regex to extract instance ID from the issue body match = re.search(r\u0026#34;EC2 instance (\\bi-\\w+\\b)\u0026#34;, issue_body) if match: return match.group(1) else: raise ValueError(\u0026#34;Instance ID not found in issue body...\u0026#34;) def reopen_issue(): repo = os.getenv(\u0026#34;GITHUB_REPO\u0026#34;, DEFAULT_GITHUB_REPO) issue_number = os.getenv(\u0026#34;GITHUB_ISSUE_NUMBER\u0026#34;, DEFAULT_GITHUB_ISSUE_NUMBER) token = os.getenv(\u0026#34;GITHUB_TOKEN\u0026#34;, DEFAULT_GITHUB_TOKEN) url = f\u0026#34;https://api.github.com/repos/{repo}/issues/{issue_number}\u0026#34; headers = {\u0026#34;Authorization\u0026#34;: f\u0026#34;token {token}\u0026#34;} data = {\u0026#34;state\u0026#34;: \u0026#34;open\u0026#34;} response = requests.patch(url, headers=headers, json=data) if response.status_code == 200: print(f\u0026#34;Issue #{issue_number} reopened successfully.\u0026#34;) else: print(f\u0026#34;Failed to reopen issue #{issue_number}: {response.text}\u0026#34;) def remediate(): issue_body = os.getenv(\u0026#34;ISSUE_BODY\u0026#34;, \u0026#34;The EC2 instance i-06771d5fe9accdc18 is currently stopped. Remediation action is required.\u0026#34;) try: instance_id = parse_issue_body(issue_body) print(f\u0026#34;Instance ID to remediate: {instance_id}\u0026#34;) start_instance(instance_id) except Exception as e: print(f\u0026#34;Error during remediation: {e}\u0026#34;) reopen_issue() if __name__ == \u0026#34;__main__\u0026#34;: remediate() 2. Resolve the issue Run the script to fix issue #3: Reformat the JSON output:\n{\u0026#39;StartingInstances\u0026#39;: [ {\u0026#39;CurrentState\u0026#39;: {\u0026#39;Code\u0026#39;: 0, \u0026#39;Name\u0026#39;: \u0026#39;pending\u0026#39; }, \u0026#39;InstanceId\u0026#39;: \u0026#39;i-06771d5fe9accdc18\u0026#39;, \u0026#39;PreviousState\u0026#39;: {\u0026#39;Code\u0026#39;: 80, \u0026#39;Name\u0026#39;: \u0026#39;stopped\u0026#39; } } ], \u0026#39;ResponseMetadata\u0026#39;: {\u0026#39;RequestId\u0026#39;: \u0026#39;b55130d0-4bd5-4937-a2de-94e1201d65e6\u0026#39;, \u0026#39;HTTPStatusCode\u0026#39;: 200, \u0026#39;HTTPHeaders\u0026#39;: {\u0026#39;x-amzn-requestid\u0026#39;: \u0026#39;b55130d0-4bd5-4937-a2de-94e1201d65e6\u0026#39;, \u0026#39;cache-control\u0026#39;: \u0026#39;no-cache, no-store\u0026#39;, \u0026#39;strict-transport-security\u0026#39;: \u0026#39;max-age=31536000; includeSubDomains\u0026#39;, \u0026#39;content-type\u0026#39;: \u0026#39;text/xml;charset=UTF-8\u0026#39;, \u0026#39;content-length\u0026#39;: \u0026#39;411\u0026#39;, \u0026#39;date\u0026#39;: \u0026#39;Wed, 21 Aug 2024 10: 13: 45 GMT\u0026#39;, \u0026#39;server\u0026#39;: \u0026#39;AmazonEC2\u0026#39; }, \u0026#39;RetryAttempts\u0026#39;: 0 } } The script only launches an instance in the issue without encountering errors (and also does not close the issue).\nCheck the instance through CloudTrail event StartInstances: Check the instance on the EC2 page and see that the times are inconsistent (on EC2 it is UTC+7 while on CloudTrail it is UTC): Thus, the detection and remediation of the stopped EC2 instance has been successfully carried out.\n"
},
{
	"uri": "/1-cpu-stress/1.5/",
	"title": "Actions workflow to Inject CPU Stress &amp; Remediate",
	"tags": [],
	"description": "",
	"content": "Reference: .github/workflows/inject-cpu-stress.yml from the repo mostlycloudysky/aws-chaos-experiments.\nAll Actions-related components use a new instance in us-east-2.\n1. Prerequisites a. Create instance b. Notification c. Setup secrets\nAccording to the reference YAML file, it is necessary to set up secrets for the action (based on the inject-cpu-stress.json file, you can determine the format of the secrets), including:\nAWS_ACCESS_KEY_ID: *** AWS_SECRET_ACCESS_KEY: *** AWS_REGION: us-east-2 (change of pace) AWS_ACCOUNT_ID: ***** INSTANCE_ID: i-**** IAM_ROLE: \u0026lt;role name after the “/” in the role ARN, e.g., HaiAnh-FIS\u0026gt; CLOUDWATCH_ALARM_NAME: CPUUtilizationAlarm GITHUB_TOKEN: Not needed because a temporary token will be created automatically each time the job runs Step 1: Go to the repository settings Step 2: In the sections on the left, below \u0026ldquo;Secrets and variables,\u0026rdquo; select Actions. Step 3: Select \u0026ldquo;New repository secret\u0026rdquo; and enter the secret name and value. However, there will be a naming violation error due to the name containing special characters. Referring to this GitHub discussion, it seems they did not fix it, so we will use HashiCorp Vault (suggested by the GitHub Action course on KodeKloud). Steps 4 to 14 use HashiCorp, but there was still an error. It turns out that there was a special character in the YAML file that was not an underscore. Just pasting it into a place without font formatting, like a URL input field, will resolve the issue.\nStep 4: Go to https://www.vaultproject.io/. Select \u0026ldquo;Try HCP Vault\u0026rdquo;. Step 5: Select Sign in with GitHub account Step 6: If you don’t have an organization, create one. If you already have one, select that organization (currently, only one organization is allowed). Step 7: Select Projects -\u0026gt; View project Step 8: Scroll down or locate the left sidebar, and select Vault Secrets Step 9: Select Create first app Step 10: Name it “AWS-FIS-secrets” and select Create App Step 11: Select Create new secret -\u0026gt; Static secret Step 12: Enter the Secret and then Save. Step 13: Select Integrations on the left sidebar -\u0026gt; GitHub Actions Step 14: Select Authorize HCP Vault Secrets The above steps demonstrate how to store secrets on Vault. Now, let\u0026rsquo;s return to storing secrets on GitHub Actions.\nStep 15: Add the secrets to the repo as in step 3 2. Set up Push the fis-templates folder, the scripts folder, and the .github folder from the sample repo to the personal repo 3. Run the workflow action Step 1: Go to the Actions tab of your personal repository, select \u0026ldquo;Inject CPU Stress Experiment\u0026rdquo; from the left sidebar -\u0026gt; Click \u0026ldquo;Run workflow\u0026rdquo; -\u0026gt; Click the green button labeled \u0026ldquo;Run workflow\u0026rdquo;. Step 2: Observe the workflow Observe the steps: The following step to create an experiment template for CPU stress was observed to be successful: Wait 20 minutes to proceed with the experiment: Observe the experiment\u0026rsquo;s execution timeline. Check the FIS console: Check alarm: Check CPUUtilizationAlarm: The alarm notifies via email: Email CPU Utilization Alarm: Everything is going according to the workflow! Once this step is completed, the following steps will finish very quickly, and the workflow will be completed: Check workflow: Not the expected flow due to CPU stress for 10 minutes and normal recovery before the experiment step completed: Therefore, when running the step “Detect Issues,” the alarm does not trigger and will not create an issue on the personal repository; in other words, there is no issue to address, so no resolution is possible: To temporarily resolve the issue, create a file named detect_cpu_stress_issues.yml (copy the content from inject-cpu-stress.yml, remove the steps related to the experiment, and keep only the Detect Issues step) for the detect cpu stress workflow and run it manually.\nProceed to rerun the experiment: The workflow inject-cpu-stress.yml handles the scenario where the experiment template already exists by retrieving the existing template ID and saving it to $GITHUB_OUTPUT for the step \u0026lsquo;Start FIS Experiment\u0026rsquo;: During the experiment, activate the Detect CPU Stress workflow: Check the detailed workflow, the issue has been created: Go to the issue just created from Action, and manually label it with \u0026lsquo;cpu-stress\u0026rsquo;: Result: Try closing the issue to see if the remediate workflow is triggered: Check Workflow remediate: Workflow details: Monitor CloudWatch CPU alarm: "
},
{
	"uri": "/2-network-latency/2.5/",
	"title": "Actions workflow to Inject Network Latency &amp; Remediate",
	"tags": [],
	"description": "",
	"content": "Reference: .github/workflows/ inject-network-latency.yml và .github/workflows/remediate-network-latency.yml của repo mostlycloudysky/aws-chaos-experiments.\n1. Prerequisites The EC2 instance, SNS, GitHub repo, and CloudWatch Alarm resources were created in the CPU Stress section.\nSetup secrets\nAccording to the reference YAML file, it\u0026rsquo;s necessary to set up the secrets for the action. However, since these were already added in the CPU Stress section, you only need to change CLOUDWATCH_ALARM_NAME to the value NetworkInAlarm.\nStep 1: Go to the settings of the repository. Step 2: On the left-hand side sections, under \u0026ldquo;Secrets and variables,\u0026rdquo; select Actions. Step 3: Select \u0026ldquo;New repository secret\u0026rdquo; and set the secret name and value. Step 4: Add the secrets to the repo\n2. Set up Push the fis-templates folder, scripts folder, and .github folder from the sample repo to your personal repo (already done in the CPU Stress section). 3. Run the workflow action a. Run the experiment\nStep 1: Go to Actions in your personal repository, select \u0026ldquo;Inject Network Latency Experiment\u0026rdquo; from the left sidebar -\u0026gt; Select Run workflow -\u0026gt; Click the green button labeled \u0026ldquo;Run workflow.\u0026rdquo; Received notification: Step 2: Observe the workflow Observe the steps: Observe the step to create an experiment template for Inject Network Latency, it was created successfully: Wait a few minutes to proceed with the experiment: Observe the timeline for running the experiment. Check the FIS console: Check details of the running Experiment: Check NetworkInAlarm: Alarm notification sent to email: Mail NetworkInAlarm: Everything is still proceeding according to the workflow! However, once this step is completed, there will be no more alarms like in the CPU Stress test part.\nb. Manually run detect\nTherefore, I created a file named detect-network-latency.yml for the workflow to detect network latency (removing the steps for creating and running experiments, and keeping the detect step from the inject-network-latency.yml file):\nManually run detect: Detect alarms and create issues on personal GitHub repo: Observe the issue in detail: c. Remediation\nStep 1: Close the issue by selecting “Close issue” to see if it triggers the remediate workflow. Step 2: Check workflow remediation: However, the remediation did not run: Although there are still pending alarms: Reviewing the workflow of inject-network-latency.yaml, the job only runs when there is a network-latency label: However, none of the files mention labeling issues; it turns out that labeling needs to be done manually. Step 3: To create a label for an issue on your personal repo, go to the \u0026ldquo;Issue\u0026rdquo; tab and select the \u0026ldquo;Labels\u0026rdquo; button next to the green \u0026ldquo;New issue\u0026rdquo; button: Step 4: Create the labels \u0026ldquo;network-latency\u0026rdquo;, \u0026ldquo;remediate\u0026rdquo;, and \u0026ldquo;cpu-stress\u0026rdquo;: Step 5: To add a label to an issue, select the issue -\u0026gt; Choose the setting next to \u0026ldquo;Labels\u0026rdquo; -\u0026gt; Select the label network-latency: Result: Step 6: Attempt to remediate by closing this issue by selecting \u0026ldquo;Close issue.\u0026rdquo;\nThe Remediate Workflow is triggered: Bước 7: Check workflow details: Step 8: Check the instance on the EC2 page. Initially, the EC2Rescue instance is created: Then, the instance for the experiment was stopped completely: The volume of the instance in the issue that was shut down has been transferred to the EC2Rescue instance: A few minutes later, the instance shuts down, the instance for the experiment is restarted, and note that the volume has been reattached: Montior NetworkIn via CloudWatch: Thus, although it is not automated because the detect part has to be run manually (due to the workflow logic where detection occurs after the experiment step), it generally resolves the issue successfully.\n"
},
{
	"uri": "/3/3.5/",
	"title": "Actions workflow to Stop EC2 Instances &amp; Remediate",
	"tags": [],
	"description": "",
	"content": "Reference: .github/workflows/stop-instances.yml and .github/workflows/remediate-stop-instances.yml from the repo mostlycloudysky/aws-chaos-experiments\n1. Prerequisites The resources for EC2 instance, SNS, and GitHub repo have been created in the CPU Stress section.\n2. Set up Push the fis-templates folder, scripts folder, and .github folder from the sample repo to the personal repo (already completed in the CPU Stress section). 3. Run the workflow action a. Run the experiment\nStep 1: Go to the Actions of your personal repo, select \u0026ldquo;Stop Instances Experiment\u0026rdquo; from the left sidebar -\u0026gt; Choose \u0026ldquo;Run workflow\u0026rdquo; -\u0026gt; Click the green button labeled \u0026ldquo;Run workflow\u0026rdquo;. Step 2: Observe the workflow Observe the steps: However, it failed to run. The step “Retrieve the latest FIS Experiment Template ID” is supposed to retrieve the template ID if it exists; if not, it returns “new” and proceeds to the “Replace” and “Create” steps. However, the log shows that these two steps did not run, which means the condition of the if statement on line template_id = new in the Retrieve step is incorrect. Upon checking, it turns out to be incorrect, so it needs to be fixed: There is still one incorrect JSON name on line 54. Please correct it: Push code to the repository:\nObserve the steps of the job: Observe the step to create an experiment template, it shows successful creation: Observe the experiment timeline. Check the FIS console: Check the details of the running Experiment: However, the Detect issues step did not detect: Diagnosis: Due to the instance stopping slower than the script execution process.\nI ran it again (added a print(response) for easier debugging) and created the issue: b. Remediation\nStep 1: To add a label to the issue, select the issue -\u0026gt; Click the settings icon next to \u0026ldquo;Labels\u0026rdquo; -\u0026gt; Choose the \u0026ldquo;remediate\u0026rdquo; label. Result: Step 2: Try to resolve it by closing this issue by selecting “Close issue”.\nThe Remediate Workflow is triggered: Step 3: Check workflow details Step 4: Check the output of the \u0026ldquo;Remediate stopped Instances\u0026rdquo; step: The current state is pending and the previous state is stopped, indicating that the instance is being restarted.\nStep 5: Check the EC2 console: Step 6: Check the CloudTrail logs: Thus, although it is not automated because the detection part needs to be run manually (due to the workflow logic where detection occurs after the experiment step), it generally resolves the issue successfully.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]